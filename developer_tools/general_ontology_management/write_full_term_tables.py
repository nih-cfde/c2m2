#!/usr/bin/env python3

##########################################################################################
#                                          SCRIPT PROVENANCE
##########################################################################################
# 
# Arthur Brady (Univ. of MD Inst. for Genome Sciences) wrote this script to automatically
# load and summarize (via term-tracking TSV files) controlled-vocabulary term usage across
# all core resource entity records in a given C2M2 submission instance to assist with
# submission preparation prior to ingestion into a central CFDE database.
# 
# Creation date: 2020-05-17
# Lastmod date unless I forgot to change it: 2021-08-04
# 
##########################################################################################

import os
import json
import re
import sys

##########################################################################################
##########################################################################################
##########################################################################################
#                                          USER-DEFINED PARAMETERS
##########################################################################################
##########################################################################################
##########################################################################################

##########################################################################################
# Directory containing full CV reference info (see below, 'cvFile' dictionary, for file
# list).

cvRefDir = '../../draft-C2M2_external_CV_term_table_generator_script/external_CV_reference_files'

##########################################################################################
# Directory into which new TSVs generated by this script will be written summarizing all
# controlled vocabulary term usage throughout this C2M2 instance.

outDir = './full_term_tables'

##########################################################################################
##########################################################################################
##########################################################################################
#                                  CONSTANT PARAMETERS: DO NOT MODIFY
##########################################################################################
##########################################################################################
##########################################################################################

##########################################################################################
# Map of CV names to reference files. These files should be present in cvRefDir before
# running this script.

cvFile = {
    
    'EDAM' : '%s/EDAM.version_1.25.tsv' % cvRefDir,
    'OBI' : '%s/OBI.version_2021-04-06.obo' % cvRefDir,
    'OBI_provisional' : '%s/OBI.provisional_terms.2021-08-04.tsv' % cvRefDir,
    'Uberon' : '%s/uberon.version_2021-02-12.obo' % cvRefDir,
    'DO' : '%s/doid.version_2021.06.08.obo' % cvRefDir
}

##########################################################################################
# Term-tracker data structure.

termsUsed = {
    
    'file_format': {},
    'data_type': {},
    'assay_type': {},
    'anatomy': {},
    'disease': {}
}

##########################################################################################
##########################################################################################
##########################################################################################
#                         SUBROUTINES (in call order, including recursion)
##########################################################################################
##########################################################################################
##########################################################################################

####### progressReport ###################################################################
# 
# CALLED BY: main execution thread
# 
# Print a logging message to STDERR.
# 
#-----------------------------------------------------------------------------------------

def progressReport( message ):
    
    print('%s' % message, file=sys.stderr)

#-----------------------------------------------------------------------------------------
# end sub: progressReport( message )
##########################################################################################

def decorateTermsUsed(  ):
    
    global termsUsed, cvFile

    for categoryID in termsUsed:
        
        if categoryID == 'anatomy' or categoryID == 'assay_type' or categoryID == 'disease':
            
            cv = ''

            if categoryID == 'anatomy':
                
                cv = 'Uberon'

            elif categoryID == 'assay_type':
                
                # Load the provisional term map first for this one; afterward we'll
                # load the main ontology with destructive overwrites for any conflicts
                # (to defer to published term versions).

                cv = 'OBI_provisional'

            elif categoryID == 'disease':
                
                cv = 'DO'

            # end if ( categoryID type check )

            if cv == 'OBI_provisional':
                
                refFile = cvFile[cv]

                with open( refFile, 'r' ) as IN:
                    
                    header = IN.readline()

                    for line in IN:
                        
                        line = line.rstrip('\r\n')

                        ( termRequester, termStatus, currentTerm, termLabel, termDefinition, termSynonyms ) = re.split(r'\t', line)

                        termsUsed[categoryID][currentTerm] = {}

                        termsUsed[categoryID][currentTerm]['name'] = termLabel
                        termsUsed[categoryID][currentTerm]['description'] = termDefinition

                        if termSynonyms == '':
                            
                            termSynonyms = '[]'

                        termsUsed[categoryID][currentTerm]['synonyms'] = termSynonyms

                    # end for ( each line in provisional OBI term TSV )

                # end with ( open [provisional OBI term TSV] as IN

                cv = 'OBI'

            # end if cv == 'OBI_provisional'

            refFile = cvFile[cv]

            with open( refFile, 'r' ) as IN:
                
                recording = False

                currentTerm = ''

                for line in IN:
                    
                    line = line.rstrip('\r\n')
                
                    matchResult = re.search(r'^id:\s+(\S.*)$', line)

                    if not( matchResult is None ):
                        
                        currentTerm = matchResult.group(1)

                        termsUsed[categoryID][currentTerm] = {}

                        recording = True

                    elif not( re.search(r'^\[Term\]', line) is None ):
                        
                        recording = False

                    elif not( re.search(r'^\[Typedef\]', line) is None ):
                        
                        break

                    elif recording:
                        
                        if not ( re.search(r'^name:\s+(\S*.*)$', line) is None ):
                            
                            termsUsed[categoryID][currentTerm]['name'] = re.search(r'^name:\s+(\S*.*)$', line).group(1)

                        elif not ( re.search(r'^def:\s+\"(.*)\"[^\"]*$', line) is None ):
                            
                            parsedDesc = re.search(r'^def:\s+\"(.*?)(?<!\\)\".*$', line).group(1)

                            if currentTerm == 'UBERON:4300002':
                                
                                # Until this is fixed in the ontology, a typo involving unpaired brackets
                                # makes this one impossible to parse properly.

                                parsedDesc = re.sub(r'\]$', r'', parsedDesc)

                            parsedDesc = re.sub(r'\s*\[[^\]]+\]', r'', parsedDesc)

                            # Remove newline codes and replace with space characters.

                            parsedDesc = re.sub(r'\\n', r' ', parsedDesc)

                            # Trim remaining extremal whitespace.

                            parsedDesc = re.sub(r'^\s+', r'', parsedDesc)
                            parsedDesc = re.sub(r'\s+$', r'', parsedDesc)

                            termsUsed[categoryID][currentTerm]['description'] = parsedDesc

                        elif not ( re.search(r'^synonym:\s+"[^\"]+"\s+EXACT', line) is None ):
                            
                            newSyn = re.search(r'^synonym:\s+"([^\"]+)"\s+EXACT', line).group(1)

                            newSyn = re.sub(r'\\n', r' ', newSyn)

                            newSyn = newSyn.strip().strip('"\'').strip()

                            newSyn = re.sub(r'\"', r'', newSyn)

                            if re.search(r'\|', newSyn) is None:
                                
                                if 'synonyms' in termsUsed[categoryID][currentTerm]:
                                    
                                    termsUsed[categoryID][currentTerm]['synonyms'] = termsUsed[categoryID][currentTerm]['synonyms'] + '|"' + newSyn + '"'

                                else:
                                    
                                    termsUsed[categoryID][currentTerm]['synonyms'] = '"' + newSyn + '"'

                        elif not ( re.search(r'^synonym:\s+"[^\"]+"\s+BROAD', line) is None ):

                            newSyn = re.search(r'^synonym:\s+"([^\"]+)"\s+BROAD', line).group(1)

                            newSyn = re.sub(r'\\n', r' ', newSyn)

                            newSyn = newSyn.strip().strip('"\'').strip()

                            newSyn = re.sub(r'\'', r'', newSyn)

                            if re.search(r'\|', newSyn) is None:

                                if 'synonyms' in termsUsed[categoryID][currentTerm]:
                                    
                                    termsUsed[categoryID][currentTerm]['synonyms'] = termsUsed[categoryID][currentTerm]['synonyms'] + '|"' + newSyn + '"'

                                else:
                                    
                                    termsUsed[categoryID][currentTerm]['synonyms'] = '"' + newSyn + '"'

                        elif not ( re.search(r'^def:\s+', line) is None ):
                            
                            die('Unparsed def-line in %s OBO file: "%s"; aborting.' % ( cv, line ) )

                    # end if ( line-type selector switch )

                # end for ( input file line iterator )

            # end with ( open refFile as IN )

        elif categoryID == 'file_format' or categoryID == 'data_type':
            
            cv = 'EDAM'

            refFile = cvFile[cv]

            with open( refFile, 'r' ) as IN:
                
                header = IN.readline()

                for line in IN:
                    
                    line = line.rstrip('\r\n')

                    ( termURL, name, synonymBlock, definition ) = re.split(r'\t', line)[0:4]

                    currentTerm = re.sub(r'^.*\/([^\/]+)$', r'\1', termURL)

                    currentTerm = re.sub(r'data_', r'data:', currentTerm)
                    currentTerm = re.sub(r'format_', r'format:', currentTerm)

                    # There are some truly screwy things allowed inside
                    # tab-separated fields in this file. Clean them up.

                    name = name.strip().strip('"\'').strip()
                    
                    synonymBlock = synonymBlock.strip().strip('"\'').strip()

                    synonymField = ''

                    if synonymBlock == '':
                        
                        synonymField = '[]'

                    else:
                        
                        synonyms = re.split(r'\|+', synonymBlock)

                        synonymField = '['

                        first = 1

                        for synonym in synonyms:
                            
                            synonym = re.sub(r'"', r'', synonym)

                            if first == 1:
                                
                                synonymField = synonymField + '"' + synonym + '"'

                                first = 0

                            else:
                                
                                synonymField = synonymField + ',"' + synonym + '"'

                        synonymField = synonymField + ']'

                    definition = definition.strip().strip('"\'').strip()

                    definition = re.sub( r'\|.*$', r'', definition )

                    if categoryID == 'file_format' and not( re.search(r'^format', currentTerm) is None ):
                        
                        termsUsed[categoryID][currentTerm] = {}

                        termsUsed[categoryID][currentTerm]['name'] = name
                        termsUsed[categoryID][currentTerm]['description'] = definition
                        termsUsed[categoryID][currentTerm]['synonyms'] = synonymField

                    elif categoryID == 'data_type' and not( re.search(r'^data', currentTerm) is None ):
                        
                        termsUsed[categoryID][currentTerm] = {}

                        termsUsed[categoryID][currentTerm]['name'] = name
                        termsUsed[categoryID][currentTerm]['description'] = definition
                        termsUsed[categoryID][currentTerm]['synonyms'] = synonymField

                # end for ( input file line iterator )

            # end with ( refFile opened as IN )

        # end if ( switch on categoryID )

    # end foreach ( categoryID in termsUsed )

# end sub decorateTermsUsed(  )

def writeTermsUsed(  ):
    
    global outDir, termsUsed

    for categoryID in termsUsed:
        
        outFile = '%s/%s.tsv' % ( outDir, categoryID )

        with open(outFile, 'w') as OUT:
            
            OUT.write( '\t'.join( [ 'id', 'name', 'description', 'synonyms' ] ) + '\n' )

            for termID in termsUsed[categoryID]:
                
                termDesc = ''

                termSynonyms = '[]'

                if 'name' in termsUsed[categoryID][termID]:
                    
                    if 'description' in termsUsed[categoryID][termID]:
                        
                        termDesc = termsUsed[categoryID][termID]['description']

                    if 'synonyms' in termsUsed[categoryID][termID]:
                        
                        termSynonyms = termsUsed[categoryID][termID]['synonyms']

                        if termSynonyms != '' and re.search(r'\|', termSynonyms) is None and re.search(r'^\[', termSynonyms) is None:
                            
                            termSynonyms = '[' + termSynonyms + ']'
                        
                        elif termSynonyms != '' and not(re.search(r'\|', termSynonyms) is None):
                            
                            synonyms = re.split(r'\|+', termSynonyms)

                            termSynonyms = '['

                            first = 1

                            for synonym in synonyms:
                                
                                if first == 1:
                                    
                                    termSynonyms = termSynonyms + synonym

                                    first = 0

                                else:
                                    
                                    termSynonyms = termSynonyms + ',' + synonym

                            termSynonyms = termSynonyms + ']'

#                    progressReport(termID)
                    OUT.write( '\t'.join( [ termID, termsUsed[categoryID][termID]['name'], termDesc, termSynonyms ] ) + '\n' )

# end sub writeTermsUsed(  )

##########################################################################################
##########################################################################################
##########################################################################################
#                                                    EXECUTION
##########################################################################################
##########################################################################################
##########################################################################################

# Create the output directory if need be.

if not os.path.isdir(outDir) and os.path.exists(outDir):
    
    die('%s exists but is not a directory; aborting.' % outDir)

elif not os.path.isdir(outDir):
    
    os.mkdir(outDir)

# Load data from CV reference files to fill out needed columns in C2M2
# term-tracker tables.

decorateTermsUsed()

# Write the term-tracker tables.

writeTermsUsed()


